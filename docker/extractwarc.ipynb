{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.archive.archivespark._\n",
    "import org.archive.archivespark.functions._\n",
    "import org.archive.archivespark.specific.warc._\n",
    "import java.io._\n",
    "\n",
    "val warc_prefix=sys.env(\"WARC_FILENAME\")\n",
    "val warcfile=\"/data/\" + warc_prefix + \".warc.gz\"\n",
    "val cdxPath =\"/results/\" + warc_prefix\n",
    "val records = ArchiveSpark.load(WarcSpec.fromFiles(warcfile))\n",
    "\n",
    "var summary = \"\"\n",
    "\n",
    "var t1 = System.nanoTime\n",
    "records.saveAsCdx(cdxPath + \"/cdx.gz\")\n",
    "var duration = (System.nanoTime - t1) / 1e9d\n",
    "summary = \"CDX:\" + duration + \"|\"\n",
    "\n",
    "t1 = System.nanoTime\n",
    "val pages = records.filter(r => r.mime == \"text/html\" && r.status == 200)\n",
    "val Links = Html.all(\"a\")\n",
    "val LinkUrls = SURT.of(HtmlAttribute(\"href\").ofEach(Links))\n",
    "val LinkTexts = HtmlText.ofEach(Links)\n",
    "val pagesWithLinks = pages.enrich(LinkUrls).enrich(LinkTexts)\n",
    "pagesWithLinks.saveAsJson(cdxPath + \"/pages-with-links.gz\")\n",
    "duration = (System.nanoTime - t1) / 1e9d\n",
    "summary = summary + \"PagesWithLinks:\" + duration + \"\\n\"\n",
    "\n",
    "val pw = new PrintWriter(new File(cdxPath + \"/\"+ warc_prefix + \"_results.txt\" ))\n",
    "pw.write(summary)\n",
    "pw.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArchiveSpark",
   "language": "",
   "name": "archivespark"
  },
  "language_info": {
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}